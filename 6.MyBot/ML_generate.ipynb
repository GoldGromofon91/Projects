{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Парсим документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Для парсинга используем библиотеку csv\n",
    "    csv.DictReader() - создает словарь из объекта *.csv ключи в котором это название столбцов (в оригинале)\n",
    "    метод fieldnames - выводит имена ключей в списке \n",
    "    strip() возвращает копию строки, в которой все символы были удалены с начала и конца строки (символом по умолчанию является пробел).\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('example.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "#     print(reader.fieldnames)\n",
    "    #Выводим содержимое всех столбцов в соответсвии с их ключами \n",
    "    lines = list(reader)\n",
    "#     print(lines[35][\"Код BOT_CONFIG\"])\n",
    "    \n",
    "all_bot_config_dict = [key['Код BOT_CONFIG'] for key in lines]\n",
    "# print(all_bot_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_codes = []\n",
    "\n",
    "for code in all_bot_config_dict:\n",
    "    #Обрезаем из строки только содержимое ключа BOT_CONFIG = {...}\n",
    "    if 'BOT_CONFIG =' in code:\n",
    "        code = code.split('BOT_CONFIG =')[1]\n",
    "    if 'def ' in code:\n",
    "        code = code.split('\\ndef ')[0]\n",
    "    #Удаляем все символы пробела в начале и в конце строки\n",
    "    code = code.strip()\n",
    "    config_codes.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "#eval- позволить считать словарь выражением и вставит его как элемент списка\n",
    "# try:\n",
    "#     response = eval(\"{'a': 'b'}\")\n",
    "#     print(response)\n",
    "# except:\n",
    "#     print(1)\n",
    "configs = []\n",
    "errors = 0\n",
    "for code in config_codes:\n",
    "    # Добавляем словарь с intentom в список, если у нас правильный словарь то функция eval обработает его как значение и поместит в список\n",
    "    #     print(code)\n",
    "    try:\n",
    "        configs.append(eval(code))\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "\n",
    "\n",
    "print(len(configs))\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_config = {\n",
    "    'intents': {},\n",
    "    'failure_phrases': []\n",
    "}\n",
    "# print(configs)\n",
    "#Переберием список словарей намерений \n",
    "for config in configs:\n",
    "#     print(type(config),len(config))\n",
    "    #Если элемент конфиг -словарь, проверяем что есть ключ intents, если да -то перебираем его по ключу и значению\n",
    "    if isinstance(config, dict):\n",
    "        if 'intents' in config:\n",
    "            for intent, value in config['intents'].items():\n",
    "#                 print(intent)\n",
    "#                 print('\\t', value)\n",
    "                #Если текущего намерения нет в отфильрованном списке, то добавляем новый словарь намерения с вопросами и ответами\n",
    "                if intent not in big_config['intents']:\n",
    "                    big_config['intents'][intent] = {\n",
    "                        'examples': [],\n",
    "                        'responses': []\n",
    "                    }\n",
    "                #Если вопросы(и ответы) это словари , то добавляем в наше новое намерение зачения в ключи examples/responses\n",
    "                if isinstance(value, dict):\n",
    "                    big_config['intents'][intent]['examples'] += value.get('examples', [])\n",
    "                    big_config['intents'][intent]['responses'] += value.get('responses', [])\n",
    "        #Добавляем из пользовательских списков намерений в наш обновленный список фразы заглушки \n",
    "        big_config['failure_phrases'] += config.get('failure_phrases', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent, value in big_config['intents'].items():\n",
    "    value['examples'] = list(set(value['examples']))\n",
    "    value['responses'] = list(set(value['responses']))\n",
    "    value['examples'] = [s.strip() for s in value['examples'] if s.strip()]\n",
    "    value['responses'] = [s.strip() for s in value['responses'] if s.strip()]\n",
    "\n",
    "big_config['failure_phrases'] = list(set(big_config['failure_phrases']))\n",
    "big_config['failure_phrases'] = [s.strip() for s in big_config['failure_phrases'] if s.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# print(big_config)\n",
    "print(type(big_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_CONFIG = big_config\n",
    "#Создаем список из данных формата [значение из examples: intent к которому относится значение] дял дальнейшей вектоиизации\n",
    "data_set = []\n",
    "for intent, intent_data in BIG_CONFIG['intents'].items():\n",
    "    for exmple_answer in intent_data['examples']:\n",
    "        data_set.append([exmple_answer,intent])\n",
    "\n",
    "# print(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем отдельно множество ответов\n",
    "X_text = [x for x, y in data_set]\n",
    "y = [y for x,y in data_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['time'], dtype='<U28')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(vectorizer.transform(['Сколько время?']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6289424860853432"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21910112359550563"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3205056179775281\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))  # Как улучшить?\n",
    "X = vectorizer.fit_transform(X_text)\n",
    "\n",
    "probas = []\n",
    "\n",
    "for i in range(10):\n",
    "    clf = LinearSVC()  # Как улучшить?\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    clf.fit(X_train, y_train)\n",
    "    proba = clf.score(X_test, y_test)\n",
    "    probas.append(proba)\n",
    "\n",
    "print(sum(probas) / len(probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
